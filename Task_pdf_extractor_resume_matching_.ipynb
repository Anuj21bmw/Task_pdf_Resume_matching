{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:07.420721Z",
          "iopub.execute_input": "2023-09-18T15:55:07.421087Z",
          "iopub.status.idle": "2023-09-18T15:55:07.495645Z",
          "shell.execute_reply.started": "2023-09-18T15:55:07.421057Z",
          "shell.execute_reply": "2023-09-18T15:55:07.494644Z"
        },
        "trusted": true,
        "id": "ou0jJ3Gmxpxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install tokenizer transformers scikit-learn pypdf==3.16.0 nltk pandarallel pandas==2.1.0 datasets\n"
      ],
      "metadata": {
        "_kg_hide-output": false,
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:07.4978Z",
          "iopub.execute_input": "2023-09-18T15:55:07.498529Z",
          "iopub.status.idle": "2023-09-18T15:55:19.933826Z",
          "shell.execute_reply.started": "2023-09-18T15:55:07.498496Z",
          "shell.execute_reply": "2023-09-18T15:55:19.932645Z"
        },
        "trusted": true,
        "id": "F1aYCwF9xpxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import datasets\n",
        "import transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:19.935663Z",
          "iopub.execute_input": "2023-09-18T15:55:19.936056Z",
          "iopub.status.idle": "2023-09-18T15:55:19.944988Z",
          "shell.execute_reply.started": "2023-09-18T15:55:19.936017Z",
          "shell.execute_reply": "2023-09-18T15:55:19.944046Z"
        },
        "trusted": true,
        "id": "vP2sUkFaxpxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumedf=pd.read_csv(\"/kaggle/input/resume-dataset/Resume/Resume.csv\")\n",
        "resumedf=resume_data.drop([\"Resume_html\"],axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:19.946787Z",
          "iopub.execute_input": "2023-09-18T15:55:19.94728Z",
          "iopub.status.idle": "2023-09-18T15:55:20.659989Z",
          "shell.execute_reply.started": "2023-09-18T15:55:19.947249Z",
          "shell.execute_reply": "2023-09-18T15:55:20.65887Z"
        },
        "trusted": true,
        "id": "Zs2QW5Qlxpxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting all text from a pdf\n",
        "from pypdf import PdfReader\n",
        "\n",
        "def pdf_text(filePath:str)->str:\n",
        "    reader = PdfReader(filePath)\n",
        "    text=\"\"\n",
        "    for page in reader.pages:\n",
        "        text+=page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:20.663625Z",
          "iopub.execute_input": "2023-09-18T15:55:20.664114Z",
          "iopub.status.idle": "2023-09-18T15:55:20.66978Z",
          "shell.execute_reply.started": "2023-09-18T15:55:20.664078Z",
          "shell.execute_reply": "2023-09-18T15:55:20.668753Z"
        },
        "trusted": true,
        "id": "H3ocVZTZxpxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doing text cleaninig and tokenization\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Define English stopwords and punctuation\n",
        "stop_words_english = set(stopwords.words(\"english\"))\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase and remove non-alphabetical characters\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text.lower())\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Initialize a list to store extracted features\n",
        "    extracted_features = []\n",
        "\n",
        "    # Define POS tags to filter out\n",
        "    pos_tags_to_filter = ['DT', 'IN', 'TO', 'PRP', 'WP']\n",
        "\n",
        "    for sent in sentences:\n",
        "        if any(criteria in sent for criteria in ['skills', 'education']):\n",
        "            # Tokenize the sentence into words\n",
        "            words = word_tokenize(sent)\n",
        "\n",
        "            # Remove stopwords and words with specific POS tags\n",
        "            filtered_words = [word for word, tag in pos_tag(words) if tag not in pos_tags_to_filter and word not in stop_words_english]\n",
        "\n",
        "            # Extend the extracted features list\n",
        "            extracted_features.extend(filtered_words)\n",
        "\n",
        "    # Join the extracted features into a single string\n",
        "    return ' '.join(extracted_features)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:20.671249Z",
          "iopub.execute_input": "2023-09-18T15:55:20.671852Z",
          "iopub.status.idle": "2023-09-18T15:55:20.683047Z",
          "shell.execute_reply.started": "2023-09-18T15:55:20.671817Z",
          "shell.execute_reply": "2023-09-18T15:55:20.682016Z"
        },
        "trusted": true,
        "id": "wKb0aSYdxpxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar=tqdm(range(len(resumedf)))\n",
        "# extract text from csv and get the text from pdf\n",
        "def process(df):\n",
        "    #uncomment when using pdf_text function .. done to save time\n",
        "    id=df['ID']\n",
        "    category=df['Category']\n",
        "    text=pdf_text(f\"/kaggle/input/resume-dataset/data/data/{category}/{id}.pdf\")\n",
        "   # text=str(df[\"Resume_str\"])\n",
        "    features=preprocess_text(text)\n",
        "    df['Feature']=features['feature']\n",
        "    progress_bar.update(1)\n",
        "    return df\n",
        "\n",
        "#applying processing to resume_data\n",
        "resumedf=resume_data.apply(process,axis=1)\n",
        "resumedf=resume_data.drop(columns=['Resume_str'])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T15:55:20.684734Z",
          "iopub.execute_input": "2023-09-18T15:55:20.685377Z",
          "iopub.status.idle": "2023-09-18T16:17:30.899791Z",
          "shell.execute_reply.started": "2023-09-18T15:55:20.685341Z",
          "shell.execute_reply": "2023-09-18T16:17:30.898659Z"
        },
        "trusted": true,
        "id": "TJwaKOmOxpxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to avoid computing again and save time\n",
        "#resume_data.to_csv(\"/path_to_save_processed_resume_data\")\n",
        "resumedf.to_csv(\"/kaggle/working/resume_data.csv\",index=False)"
      ],
      "metadata": {
        "id": "VT1l3lyCxpxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resume_data=pd.read_csv(\"/path_to_save_processed_resume_data\")\n",
        "resumedf=pd.read_csv(\"/kaggle/working/resume_data.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:17:30.901272Z",
          "iopub.execute_input": "2023-09-18T16:17:30.901672Z",
          "iopub.status.idle": "2023-09-18T16:17:31.113866Z",
          "shell.execute_reply.started": "2023-09-18T16:17:30.901636Z",
          "shell.execute_reply": "2023-09-18T16:17:31.112864Z"
        },
        "trusted": true,
        "id": "YfA_9JTwxpxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumedf.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:17:31.115274Z",
          "iopub.execute_input": "2023-09-18T16:17:31.115665Z",
          "iopub.status.idle": "2023-09-18T16:17:31.126367Z",
          "shell.execute_reply.started": "2023-09-18T16:17:31.11563Z",
          "shell.execute_reply": "2023-09-18T16:17:31.125347Z"
        },
        "trusted": true,
        "id": "sHweVUT2xpxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumedf['Category'].value_counts().sort_index().plot(kind=\"bar\",figsize=(12,6))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:17:31.128276Z",
          "iopub.execute_input": "2023-09-18T16:17:31.128971Z",
          "iopub.status.idle": "2023-09-18T16:17:31.581423Z",
          "shell.execute_reply.started": "2023-09-18T16:17:31.128936Z",
          "shell.execute_reply": "2023-09-18T16:17:31.580543Z"
        },
        "trusted": true,
        "id": "9I7jVj7txpxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_desc=15\n",
        "\n",
        "description=pd.read_csv(\"/kaggle/input/resume-and-job-description/training_data.csv\")\n",
        "\n",
        "description=description[[\"description\",\"position_title\"]][:num_desc]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:17:31.582903Z",
          "iopub.execute_input": "2023-09-18T16:17:31.583498Z",
          "iopub.status.idle": "2023-09-18T16:17:32.047978Z",
          "shell.execute_reply.started": "2023-09-18T16:17:31.583451Z",
          "shell.execute_reply": "2023-09-18T16:17:32.046919Z"
        },
        "trusted": true,
        "id": "N3MDiLZPxpx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "description['Features']=description['job_description'].apply(lambda x : preprocess_text(x)['feature'])"
      ],
      "metadata": {
        "id": "HI8aZNcMxpx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description_df2=description_df2[[\"description\",\"position_title\"]][:num_desc]\n",
        "description_df2['Features']=description_df2['description'].apply(lambda x : preprocess_text(x)['feature'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:24:00.497266Z",
          "iopub.execute_input": "2023-09-18T16:24:00.497854Z",
          "iopub.status.idle": "2023-09-18T16:24:00.930481Z",
          "shell.execute_reply.started": "2023-09-18T16:24:00.497822Z",
          "shell.execute_reply": "2023-09-18T16:24:00.929394Z"
        },
        "trusted": true,
        "id": "lG-f5wOpxpx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description_df2.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:24:08.313714Z",
          "iopub.execute_input": "2023-09-18T16:24:08.314297Z",
          "iopub.status.idle": "2023-09-18T16:24:08.325613Z",
          "shell.execute_reply.started": "2023-09-18T16:24:08.314259Z",
          "shell.execute_reply": "2023-09-18T16:24:08.324397Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "u9-Sznr-xpx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Determine the device (GPU if available, otherwise CPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "def get_embeddings(text):\n",
        "    # Tokenize and encode the input text and move it to the selected device\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "\n",
        "    # Forward pass through the model and get the embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the mean of the embeddings over the tokens\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:17:32.500481Z",
          "iopub.execute_input": "2023-09-18T16:17:32.501886Z",
          "iopub.status.idle": "2023-09-18T16:17:34.484393Z",
          "shell.execute_reply.started": "2023-09-18T16:17:32.501858Z",
          "shell.execute_reply": "2023-09-18T16:17:34.483395Z"
        },
        "trusted": true,
        "id": "Sj_Cv9brxpx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "job_desc_embeddings = np.array([get_embeddings(desc) for desc in job_description['Features']])\n",
        "resume_embeddings = np.array([get_embeddings(text) for text in resume_data['Feature']])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:17:34.485887Z",
          "iopub.execute_input": "2023-09-18T16:17:34.486463Z",
          "iopub.status.idle": "2023-09-18T16:18:44.406368Z",
          "shell.execute_reply.started": "2023-09-18T16:17:34.486426Z",
          "shell.execute_reply": "2023-09-18T16:18:44.405195Z"
        },
        "trusted": true,
        "id": "J4VFAxC0xpx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sqeezing job embeding\n",
        "resume_embeddings = resume_embeddings.squeeze()\n",
        "job_desc_embeddings = job_desc_embeddings.squeeze()\n",
        "\n",
        "print(\"Resume Embeddings Shape:\", resume_embeddings.shape)\n",
        "print(\"Job Description Embeddings Shape:\", job_desc_embeddings.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.408194Z",
          "iopub.execute_input": "2023-09-18T16:18:44.40855Z",
          "iopub.status.idle": "2023-09-18T16:18:44.415746Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.408516Z",
          "shell.execute_reply": "2023-09-18T16:18:44.414807Z"
        },
        "trusted": true,
        "id": "jDhEkjiZxpx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a DataFrame to store the results\n",
        "result_df = pd.DataFrame(columns=['jobId', 'resumeId', 'similarity', 'domainResume', 'domainDesc'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.417203Z",
          "iopub.execute_input": "2023-09-18T16:18:44.417789Z",
          "iopub.status.idle": "2023-09-18T16:18:44.427152Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.417757Z",
          "shell.execute_reply": "2023-09-18T16:18:44.426208Z"
        },
        "trusted": true,
        "id": "gwuooXjKxpx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize an empty DataFrame to store the results\n",
        "result_df = pd.DataFrame(columns=['job_desc_id', 'resume_id', 'similarity', 'work_domain', 'job_title'])\n",
        "\n",
        "# Define the number of top-k similar resumes to retrieve\n",
        "k = 10\n",
        "\n",
        "# Iterate over job descriptions\n",
        "for i, job_desc_emb in enumerate(job_desc_embeddings):\n",
        "    job_desc_id = i\n",
        "    job_title = job_description['position_title'].iloc[i]\n",
        "\n",
        "    # Compute cosine similarities between the current job description and all resumes\n",
        "    similarities = cosine_similarity([job_desc_emb], resume_embeddings)\n",
        "\n",
        "    # Get the indices of the top-k most similar resumes\n",
        "    top_k_indices = np.argsort(similarities[0])[::-1][:k]\n",
        "\n",
        "    # Extract the relevant information and add it to the result DataFrame\n",
        "    result_df = pd.concat([\n",
        "        result_df,\n",
        "        pd.DataFrame({\n",
        "            'job_desc_id': [job_desc_id] * k,\n",
        "            'resume_id': resume_data['ID'].iloc[top_k_indices].tolist(),\n",
        "            'similarity': similarities[0][top_k_indices],\n",
        "            'work_domain': resume_data['Category'].iloc[top_k_indices].tolist(),\n",
        "            'job_title': [job_title] * k\n",
        "        })\n",
        "    ])\n",
        "\n",
        "# Sort the results by similarity score (descending)\n",
        "result_df = result_df.sort_values(by='similarity', ascending=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.428726Z",
          "iopub.execute_input": "2023-09-18T16:18:44.429095Z",
          "iopub.status.idle": "2023-09-18T16:18:44.735196Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.429064Z",
          "shell.execute_reply": "2023-09-18T16:18:44.7339Z"
        },
        "trusted": true,
        "id": "p1UdPAbixpx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.739327Z",
          "iopub.execute_input": "2023-09-18T16:18:44.740435Z",
          "iopub.status.idle": "2023-09-18T16:18:44.758461Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.740377Z",
          "shell.execute_reply": "2023-09-18T16:18:44.757281Z"
        },
        "trusted": true,
        "id": "Fu20nSBWxpx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_group=result_df.groupby(\"jobId\")\n",
        "result_group"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.759986Z",
          "iopub.execute_input": "2023-09-18T16:18:44.760738Z",
          "iopub.status.idle": "2023-09-18T16:18:44.76873Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.760698Z",
          "shell.execute_reply": "2023-09-18T16:18:44.767832Z"
        },
        "trusted": true,
        "id": "G4uIK2OIxpx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example of group data\n",
        "result_group.get_group(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.77015Z",
          "iopub.execute_input": "2023-09-18T16:18:44.77124Z",
          "iopub.status.idle": "2023-09-18T16:18:44.789378Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.771208Z",
          "shell.execute_reply": "2023-09-18T16:18:44.78834Z"
        },
        "trusted": true,
        "id": "8Iys8uCZxpx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_desc):\n",
        "    print()\n",
        "    print(\"jobId---cosineSimilarity---domainResume---domainDesc\")\n",
        "    print(result_group.get_group(i).values[0])\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-18T16:18:44.790787Z",
          "iopub.execute_input": "2023-09-18T16:18:44.791404Z",
          "iopub.status.idle": "2023-09-18T16:18:44.809951Z",
          "shell.execute_reply.started": "2023-09-18T16:18:44.791372Z",
          "shell.execute_reply": "2023-09-18T16:18:44.809Z"
        },
        "trusted": true,
        "id": "UctB2c-3xpx6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}